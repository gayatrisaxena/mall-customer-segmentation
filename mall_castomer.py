# -*- coding: utf-8 -*-
"""Mall castomer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jkRnPTcmS05Q41dSx2xvJXYNYBCDLIeY
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
path = r'/content/mall castomer.csv 5.csv'
df = pd.read_csv(path)
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="sklearn.cluster._kmeans")

"""**Explore Data**"""

df.head(8)

df.shape

"""Information about all the columns in the Dataset"""

df.info()

df.describe()

df.isnull().values.any()

"""**Data Visulizations**

Male vs Female Ratio:
"""

import matplotlib.pyplot as plt

labels = ['Female', 'Male']
size = df ['Gender'].value_counts()
colors = ['lightgreen', 'yellow']
explode = [0, 0.1]
plt.rcParams['figure.figsize'] = (6, 6)
plt.pie(size, colors = colors, explode = explode, labels = labels, shadow = True, autopct = '%.2f%%' )
plt.title('Gender', fontsize = 20)
plt.axis('off')
plt.legend()
plt.show()

import seaborn as sns
sns.barplot(df)

import seaborn as sns
sns.histplot(df)

#Distribution of Annnual Income
plt.figure(figsize=(8, 6))
sns.set(style = 'whitegrid')
sns.distplot(df['Annual Income (k$)'])
plt.title('Distribution of Annual Income (k$)', fontsize = 13)
plt.xlabel('Range of Annual Income (k$)')
plt.ylabel('Count')

sns.lmplot(x = "Age", y = "Spending Score (1-100)", data = df, hue = "Gender")

"""**# Data Cleaning**

1.Locate Missing Data
"""

df.isnull()

df.isnull().sum()

""" 2.Check duplicate data"""

df.duplicated()

df.drop_duplicates()

df['Gender'] = df['Gender'].apply(lambda x: 1 if x == 'Male' else 0,)
df.head()

""" 3.Detect Outliers"""

# Calculate the first quartile (Q1) and third quartile (Q3)
Q1 = df['Spending Score (1-100)'].quantile(0.25)
Q3 = df['Spending Score (1-100)'].quantile(0.75)

# Calculate the interquartile range (IQR)
IQR = Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
print(lower_bound)
print(upper_bound)
# Detect and print outliers
outliers = df[(df['Spending Score (1-100)'] < lower_bound) | (df['Spending Score (1-100)'] > upper_bound)]
print("Outliers:")
print(outliers)

# Calculate the first quartile (Q1) and third quartile (Q3)
Q1 = df['Annual Income (k$)'].quantile(0.25)
Q3 = df['Annual Income (k$)'].quantile(0.75)

# Calculate the interquartile range (IQR)
IQR = Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
print(lower_bound)
print(upper_bound)
# Detect and print outliers
outliers = df[(df['Annual Income (k$)'] < lower_bound) | (df['Annual Income (k$)'] > upper_bound)]
print("Outliers:")
print(outliers)

# Calculate the first quartile (Q1) and third quartile (Q3)
Q1 = df['Age'].quantile(0.25)
Q3 = df['Age'].quantile(0.75)

# Calculate the interquartile range (IQR)
IQR = Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
print(lower_bound)
print(upper_bound)
# Detect and print outliers
outliers = df[(df['Age'] < lower_bound) | (df['Age'] > upper_bound)]
print("Outliers:")
print(outliers)

# Remove outliers from the DataFrame
df_no_outliers = df[(df['Annual Income (k$)'] >= lower_bound) & (df['Annual Income (k$)'] <= upper_bound)]

# Print the DataFrame without outliers
print("DataFrame without outliers:")
print(df_no_outliers)

"""clustering based on 2 features"""

#We take just the Annual Income and Spending score
df1=df[["CustomerID","Gender","Age","Annual Income (k$)","Spending Score (1-100)"]]
X=df1[["Annual Income (k$)","Spending Score (1-100)"]]
#The input data
X.head()

"""Now we calculate the Within Cluster Sum of Squared Errors (WSS) for different values of k. Next, we choose the k for which WSS first starts to diminish. This value of K gives us the best number of clusters to make from the raw data."""

from sklearn.cluster import KMeans
wcss=[]
for i in range(1,11):
    km=KMeans(n_clusters=i)
    km.fit(X)
    wcss.append(km.inertia_)
#The elbow curve
plt.plot(range(1,11), wcss, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Sum of Squared Distances')
plt.show()

"""**Clustering**

k-means

"""

#Taking 5 clusters
km=KMeans(n_clusters=5)
#Fitting the input data
km.fit(X)
#predicting the labels of the input data
y=km.predict(X)
print(y)
#adding the labels to a column named label
df1["label"] = y
#The new dataframe with the clustering done
df1.head()
print("result")
print(df1.head())

#Scatterplot of the clusters
plt.figure(figsize=(10,6))
sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)',hue="label",palette=['green','orange','red','blue','pink'], legend='full',data = df1,s = 60 )
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Spending Score (1-100) vs Annual Income (k$)')
plt.show()

df2=df[["CustomerID","Gender","Age","Annual Income (k$)","Spending Score (1-100)"]]
X=df2[["Annual Income (k$)","Spending Score (1-100)"]]
#Taking the features
X2=df2[["Age","Annual Income (k$)","Spending Score (1-100)"]]
#Now we calculate the Within Cluster Sum of Squared Errors (WSS) for different values of k.
wcss = []
for k in range(1,11):
    kmeans = KMeans(n_clusters=k, init="k-means++")
    kmeans.fit(X2)
    wcss.append(kmeans.inertia_)
plt.figure(figsize=(12,6))
plt.plot(range(1,11),wcss, linewidth=2, color="red", marker ="8")
plt.xlabel("K Value")
plt.xticks(np.arange(1,11,1))
plt.ylabel("WCSS")
plt.show()

#We choose the k for which WSS starts to diminish
km2 = KMeans(n_clusters=5)
y2 = km.fit_predict(X2)
df2["label"] = y2
#The data with labels
df2.head()

#3D Plot as we did the clustering on the basis of 3 input features
fig = plt.figure(figsize=(20,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(df2.Age[df2.label == 0], df2["Annual Income (k$)"][df2.label == 0], df2["Spending Score (1-100)"][df2.label == 0], c='purple', s=60)
ax.scatter(df2.Age[df2.label == 1], df2["Annual Income (k$)"][df2.label == 1], df2["Spending Score (1-100)"][df2.label == 1], c='red', s=60)
ax.scatter(df2.Age[df2.label == 2], df2["Annual Income (k$)"][df2.label == 2], df2["Spending Score (1-100)"][df2.label == 2], c='blue', s=60)
ax.scatter(df2.Age[df2.label == 3], df2["Annual Income (k$)"][df2.label == 3], df2["Spending Score (1-100)"][df2.label == 3], c='green', s=60)
ax.scatter(df2.Age[df2.label == 4], df2["Annual Income (k$)"][df2.label == 4], df2["Spending Score (1-100)"][df2.label == 4], c='yellow', s=60)
ax.view_init(35, 185)
plt.xlabel("Age")
plt.ylabel("Annual Income (k$)")
ax.set_zlabel('Spending Score (1-100)')
plt.show()

kmeans = KMeans(n_clusters=5, random_state=0)
kmeans.fit(df2)
print(f"Inertia: {kmeans.inertia_}")

from sklearn.metrics import silhouette_score
silhouette_avg = silhouette_score(df2, kmeans.labels_)
print(f"Silhouette Score: {silhouette_avg}")
from sklearn.metrics import davies_bouldin_score
db_index = davies_bouldin_score(df2, kmeans.labels_)
print(f"Davies-Bouldin Index: {db_index}")

cust1=df2[df2["label"]==1]
print('Number of customer in 1st group=', len(cust1))
print('They are -', cust1["CustomerID"].values)
print("--------------------------------------------")
cust2=df2[df2["label"]==2]
print('Number of customer in 2nd group=', len(cust2))
print('They are -', cust2["CustomerID"].values)
print("--------------------------------------------")
cust3=df2[df2["label"]==0]
print('Number of customer in 3rd group=', len(cust3))
print('They are -', cust3["CustomerID"].values)
print("--------------------------------------------")
cust4=df2[df2["label"]==3]
print('Number of customer in 4th group=', len(cust4))
print('They are -', cust4["CustomerID"].values)
print("--------------------------------------------")
cust5=df2[df2["label"]==4]
print('Number of customer in 5th group=', len(cust5))
print('They are -', cust5["CustomerID"].values)
print("--------------------------------------------")